{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вашей компании выпала возможность помочь миру путем обучения модели для контроля ношения масок людьми. При этом вы хотите сравнить два типа изученных детекторов (одноуровневые и двухуровневые) и предоставить небольшой отчет своему руководству. Для того, чтобы обосновать коллегам выбор модели, вы решили использовать метрики Intersection over Union и Average Precision.\n",
    "\n",
    "Данные для обучения находятся на платформе Kaggle. https://www.kaggle.com/andrewmvd/face-mask-detection\n",
    "\n",
    "Набор данных состоит из 853 изображений.\n",
    "\n",
    "Ваша основная цель — добиться Average precision > 0.85 на валидационной выборке для каждой модели. Не забудьте про визуализацию результатов.\n",
    "\n",
    "Tasks:\n",
    "* Скачать и загрузить датасет;\n",
    "* Отрисовать один батч загруженных данных;\n",
    "* Выбрать предобученную модель и обосновать свой выбор в комментарии;\n",
    "* Обучить два детектора объектов, используя выбранную модель;\n",
    "* Визуализировать предсказания моделей;\n",
    "* Посчитать метрики IoU и AP для каждой модели и построить графики Precision-Recall;\n",
    "* Описать полученные результаты в текстовой ячейке ноутбука.\n",
    "\n",
    "\n",
    "Criterias:\n",
    "* Данные загружены с помощью DataLoader\n",
    "* Используется предобученная модель и её выбор обоснован в комментариях\n",
    "* Обучены детекторы семейства RCNN и YOLO\n",
    "* Обучение происходит на обучающей выборке\n",
    "* AP на валидационной выборке двух детекторов > 0.85\n",
    "* Полученные результаты визуализированы\n",
    "* Код читаем и понятен, добавлены комментарии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': tensor(0, dtype=torch.int32),\n",
      " 'map': tensor(0.6000),\n",
      " 'map_50': tensor(1.),\n",
      " 'map_75': tensor(1.),\n",
      " 'map_large': tensor(0.6000),\n",
      " 'map_medium': tensor(-1.),\n",
      " 'map_per_class': tensor(-1.),\n",
      " 'map_small': tensor(-1.),\n",
      " 'mar_1': tensor(0.6000),\n",
      " 'mar_10': tensor(0.6000),\n",
      " 'mar_100': tensor(0.6000),\n",
      " 'mar_100_per_class': tensor(-1.),\n",
      " 'mar_large': tensor(0.6000),\n",
      " 'mar_medium': tensor(-1.),\n",
      " 'mar_small': tensor(-1.)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "preds = [\n",
    "    dict(\n",
    "      boxes=torch.tensor([[258.0, 41.0, 606.0, 285.0]]),\n",
    "      scores=torch.tensor([0.536]),\n",
    "      labels=torch.tensor([0]),\n",
    "    )\n",
    "  ]\n",
    "target = [\n",
    "    dict(\n",
    "      boxes=torch.tensor([[214.0, 41.0, 562.0, 285.0]]),\n",
    "      labels=torch.tensor([0]),\n",
    "    )\n",
    "  ]\n",
    "metric = MeanAveragePrecision()\n",
    "metric.update(preds, target)\n",
    "from pprint import pprint\n",
    "pprint(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n",
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "target = torch.tensor([0, 1, 2, 3,3,3])\n",
    "preds = torch.tensor([0, 2, 1, 3,1,3])\n",
    "\n",
    "  # Сalculating and printing the result\n",
    "precis = torchmetrics.Accuracy(task='multiclass', num_classes=4)\n",
    "recall = torchmetrics.Recall(task='multiclass', num_classes=4)\n",
    "print(precis(preds, target))\n",
    "print(recall(preds, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOOTH = 1e-6\n",
    "\n",
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    \n",
    "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    \n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean() if you are interested in average across the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      2\u001b[0m p \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m \u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([5, 3, 2])\n",
    "p = torch.tensor([1, 2, 1])\n",
    "\n",
    "(t & p).float().sum((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
